---
layout: post_bs
title: ES部分要点
category: programming
author: 周红建
date:   2018-10-7
tags: ES
---
<!-- # ES部分要点 -->
elasticsearch部分原理总结

## 1. 倒排索引

* 正排索引：文档id到文档内容、单词
* 倒排索引：单词到文档id
* 应用：搜索引擎：关键字查询文档id，倒排索引。文档id获取查询的信息，正排索引。
* 倒排索引的组成：
  * 单词词典    index中一个字段的所有记录的分词，构成一颗B+树
  * 倒排列表    分词对应的文档集合，包括分词所在的文档ids、单词频率、位置、偏移等

## 2. 分词

* 分词  文本转换成一系列单词
* 分词器  转换工具
* 三部分组成：
    1. Character Filters :原始文本处理
    2. Tokenizer:分词
    3. Token Filter:对Tokenizer切分后的单词进行处理

## 3. mapping

## 4. 集群

* cerebro 集群插件

* cluster state,记录集群信息，有版本概念

* node类型:
  * master，可以修改Cluster state信息
  * master-eligible，可被选举节点  配置信息中node.master=true
  * coordinating，处理请求的节点
  * data，数据存储节点  配置中信息node.data=true
* 服务可用性：通过多节点来解决

* 数据可用性：通过副本来解决，每个节点都有完备的数据。分片可以增大系统容量，将索引分片。

一个索引可以有多个分片，也可以有多个副本。  
分片数指定后不能修改，所以索引的容量就是一定。在分片都被分布到各个节点之后，增加节点数不能提升容量。
增加节点数，设置更多的副本在新增节点上，可以提升读取吞吐量。

* 集群的三个状态：green、yellow、red

* 文档在分片上的存储：  
  * hash算法+取余
  * 确定分片后，请求对应主分片新增文档，新建后通知副本分片也新增文档

* 脑裂问题

    选举条件：
    在配置中设置一个discovery.zen.mininum_master_nodes值(在脑裂前quorum = master-eligible节点/2+1，用quorum表示)。

    然后在脑裂分区中计算，当脑裂分区中master-eligible节点数等于大于配置中的值，这个分区才可以进行选举。达不到要求的分区就不会去选取master节点。

* 倒排索引不可变更：
  * 优点：避免并发写、生成缓存不用修改、结构固定可以压缩
  * 缺点：新文档写入，会导致重构倒排索引，替换老文件，在上述操作完成后才能进行查询，如果原有数据量非常大，那么这个重构过程的耗时也比较长，导致实时性比较差
  * 优化：只用新的文档构建一个新的倒排索引，然后与老的倒排索引同时开放查询，然后将查询结构进行汇总返回给用户

    lucene采用这种方案：

    * 单个的倒排索引成为segment，这些segment+Commit Point叫做lecene的index。
      * ES中的一个shard对应lecene的一个index。
      * Commit Point用来记录segment的信息，从而直到查询的时候该查询多少个segment。
    * put新建的文档，首先会被放在一个index buffer中，当将refresh发生的时候，将index buffer中的文档清空，然后在内存中用这些文档生成一个可以被查询segment。最后会通过flush落盘。
    * refresh：将数据刷入文件系统缓存，es默认的refresh间隔为一秒，所以新增文档最快可以在一秒后就可以被查询到，这就是近实时性的由来。
    * 发生时机：1、间隔时间到达 2、buffer满了 3、flush

    问题：当在内存中生成了segment后，突然宕机，那么这部分新数据就会丢失。
    * translog：在文档写入index buffer的时候，同时会写入translog。translog会即时写入磁盘中生成文件（可以通过index.translog设置落盘间隔，默认是每个请求都落）。
    * 可以类比数据库。因为es和数据库中的数据，存储在硬盘上的结构是经过特殊处理计算得到的，所以从收到数据经过计算到落盘整个过程比较长。所以出现突然断电之类的突发情况就会导致消息丢失，那么在这种情况下，我们在收到请求后直接把请求相关的内容进行记录到磁盘上，这个过程会比较简单，通过也防止了数据丢失问题。
    * flush：
        1. translog写入磁盘
        2. index buffer清空，生成内容segment
        3. 更新commit point，写入磁盘
        4. 内存segment写入磁盘
        5. 删除旧的translog
    * segment merging：

        refresh的速度很快，会生成很多个segment；es会在后台将segment进行合并
* 文档新增：上述就是原理
* 文档删除：.del文件记录文档在lucene的id，在查询结果中进行过滤
* 文档更新：删除旧的，创建新的
* Search运行机制
    1. Query阶段
        search request发给CoordinatingNode
        CoordinatingNode查找内容不重复的所有分片，发送search request
        三个分片查询排序后，将结果的ID返回给CoordinatingNode
    2. Fetch阶段
        CoordinatingNode整合排序文档id，向分片节点发送mutil_get请求来获取文档数据返回